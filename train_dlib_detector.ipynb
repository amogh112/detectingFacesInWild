{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import glob\n",
    "import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.cElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from skimage.feature import hog\n",
    "from skimage import data,exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_bagamoyo_data = '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_subject_videos = path_folder_bagamoyo_data + 'bagamoyo_videos/subject_sorted_videos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_framewise_videos = path_folder_bagamoyo_data + 'bagamoyo_frames_folder_wise/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/1/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/10/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/11/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/12/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/13/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/2/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/3/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/4/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/5/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/6/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/7/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/8/',\n",
       " '/media/amogh/Stuff/CMU/datasets/bagamoyo_data/bagamoyo_videos/subject_sorted_videos/9/']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_path_subject_folders = glob.glob(path_folder_subject_videos+'/*/')\n",
    "list_path_subject_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder_data = 'faces/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subjects to use for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_training_subjects = []\n",
    "list_testing_subjects = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data (frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListSubjectVideos(path_folder_subject_videos, subject_num):\n",
    "    \"\"\"\n",
    "    Returns the path to a particular subject's videos given the path to folder of subject videos and subject number\n",
    "    \"\"\"\n",
    "    path_subject_videos = path_folder_subject_videos + str(subject_num) +'/'\n",
    "    list_subject_videos = glob.glob(path_subject_videos + '/*')\n",
    "    return list_subject_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPathFolderFrames(base_name_video, path_folder_frames_wise):\n",
    "    \"\"\"\n",
    "    Returns the path of the folder with frames given the name of the video.\n",
    "    Eg- VIDEO_00-male-surprise_20180517_050935_780615161 is the videlo basename\n",
    "    returns the path <path_to_bagamoyo_frames_folder_wise>/VIDEO_00-male-surprise_20180517_050935_780615161 (5-29-2018 10-05-16 AM)\n",
    "    \"\"\"\n",
    "    list_folders = glob.glob(path_folder_frames_wise + '/*')\n",
    "    path_frames_folder = ''\n",
    "    for folder in list_folders:\n",
    "        if base_name_video in folder:\n",
    "            path_frames_folder = folder\n",
    "    return path_frames_folder    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainTestData(list_train_test_subjects,path_folder_subject_videos, path_folder_data):\n",
    "    \"\"\"\n",
    "    Copies the images from the train and test folders in the faces folder given the list with number of subjects.\n",
    "    \"\"\"\n",
    "    for subject_num in list_train_test_subjects:\n",
    "        list_subject_videos = getListSubjectVideos(path_folder_subject_videos,subject_num)\n",
    "        #get images from the relevant folder and save in faces\n",
    "        for video in tqdm(list_subject_videos):\n",
    "            basename_folder_video = os.path.splitext(os.path.basename(video))[0]\n",
    "            #get the folder with the frames\n",
    "            path_folder_frames = getPathFolderFrames(basename_folder_video,path_folder_framewise_videos)\n",
    "            list_path_frames = glob.glob(path_folder_frames + '/*.jpg')\n",
    "            for path_frame in list_path_frames:\n",
    "                print(path_frame, path_folder_data)\n",
    "                copy(path_frame, path_folder_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#convert to code cell\n",
    "generateTrainTestData([7,8,9], path_folder_subject_videos,path_folder_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the training.xml and testing.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim- \n",
    "training subjects\n",
    " - get video names of these subjects\n",
    "    - get frame names under these subjects\n",
    "    - get boxes under these frames (from data xml(generate for all videos in a folder))\n",
    "        - put in training boxes.\n",
    "        - put in test boxes.        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the xml for complete data from csv using the script written earlier.\n",
    "Given the subject numbers, take those videos, get all frames in them, get all elements in them and make training and test xml before starting the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 9]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(list(range(10)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataXML(list_subject_num,path_data_xml,path_output,subsample=True):\n",
    "    #parsing data and creating dictionary\n",
    "    tree = ET.parse(path_data_xml)\n",
    "    root = tree.getroot()\n",
    "    dic_file_to_image = {}\n",
    "    for image in root.iter('image'):\n",
    "        dic_file_to_image[image.attrib['file']] = image\n",
    "#     print((dic_file_to_image.keys()))\n",
    "    \n",
    "    #Writing an XML\n",
    "    root = ET.Element(\"dataset\")\n",
    "    name = ET.SubElement(root, \"name\").text = \"Labelled faces\"\n",
    "    comment = ET.SubElement(root, \"comment\").text = \"These are labelled images from Bagamoyo\"\n",
    "    images = ET.SubElement(root, \"images\")\n",
    "    \n",
    "    #get the list of images\n",
    "    for subject_num in list_subject_num:\n",
    "        list_subject_videos = getListSubjectVideos(path_folder_subject_videos,subject_num)\n",
    "        #get images from the relevant folder and save in faces\n",
    "        for video in tqdm(list_subject_videos):\n",
    "            basename_folder_video = os.path.splitext(os.path.basename(video))[0]\n",
    "            #get the folder with the frames\n",
    "            path_folder_frames = getPathFolderFrames(basename_folder_video,path_folder_framewise_videos)\n",
    "            list_path_frames = glob.glob(path_folder_frames + '/*.jpg')\n",
    "            print(\"{} frames present\".format(len(list_path_frames)))\n",
    "            i=0\n",
    "            for path_frame in list_path_frames:\n",
    "#                 get the frame tag in xml, if present append.\n",
    "                image_file_name = os.path.basename(path_frame)\n",
    "                if image_file_name in dic_file_to_image:\n",
    "                    im_node = dic_file_to_image[image_file_name]\n",
    "                    images.append(im_node)\n",
    "                    pass\n",
    "                else:\n",
    "                    i+=1\n",
    "            print(\"{} frames with no detection\".format(i))\n",
    "    num_images = len(images)\n",
    "    print(num_images)\n",
    "    index_ignore = random.sample(list(range(num_images)), num_images-2000)\n",
    "    print(len(index_ignore))\n",
    "    for j,image in enumerate(images):\n",
    "        if j in index_ignore:\n",
    "            par = image.getparent()\n",
    "            par.remove(image)\n",
    "    print(len(images))\n",
    "    #get 2000 random samples.\n",
    "    #write the XML file\n",
    "#     tree = ET.ElementTree(root)\n",
    "#     dest_name = path_output\n",
    "#     tree.write(dest_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 380.04it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 234.62it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 205.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 frames present\n",
      "19 frames with no detection\n",
      "119 frames present\n",
      "0 frames with no detection\n",
      "136 frames present\n",
      "14 frames with no detection\n",
      "142 frames present\n",
      "8 frames with no detection\n",
      "257 frames present\n",
      "136 frames with no detection\n",
      "150 frames present\n",
      "4 frames with no detection\n",
      "135 frames present\n",
      "0 frames with no detection\n",
      "100 frames present\n",
      "99 frames with no detection\n",
      "420 frames present\n",
      "315 frames with no detection\n",
      "134 frames present\n",
      "4 frames with no detection\n",
      "143 frames present\n",
      "2 frames with no detection\n",
      "140 frames present\n",
      "3 frames with no detection\n",
      "172 frames present\n",
      "7 frames with no detection\n",
      "233 frames present\n",
      "11 frames with no detection\n",
      "149 frames present\n",
      "19 frames with no detection\n",
      "131 frames present\n",
      "1 frames with no detection\n",
      "161 frames present\n",
      "2 frames with no detection\n",
      "129 frames present\n",
      "0 frames with no detection\n",
      "248 frames present\n",
      "131 frames with no detection\n",
      "105 frames present\n",
      "3 frames with no detection\n",
      "141 frames present\n",
      "1 frames with no detection\n",
      "155 frames present\n",
      "1 frames with no detection\n",
      "137 frames present\n",
      "1 frames with no detection\n",
      "176 frames present\n",
      "5 frames with no detection\n",
      "145 frames present\n",
      "15 frames with no detection\n",
      "699 frames present\n",
      "531 frames with no detection\n",
      "130 frames present\n",
      "2 frames with no detection\n",
      "111 frames present\n",
      "2 frames with no detection\n",
      "101 frames present\n",
      "99 frames with no detection\n",
      "124 frames present\n",
      "0 frames with no detection\n",
      "42 frames present\n",
      "42 frames with no detection\n",
      "118 frames present\n",
      "0 frames with no detection\n",
      "85 frames present\n",
      "85 frames with no detection\n",
      "127 frames present\n",
      "3 frames with no detection\n",
      "110 frames present\n",
      "2 frames with no detection\n",
      "239 frames present\n",
      "122 frames with no detection\n",
      "84 frames present\n",
      "84 frames with no detection\n",
      "96 frames present\n",
      "96 frames with no detection\n",
      "126 frames present\n",
      "0 frames with no detection\n",
      "195 frames present\n",
      "12 frames with no detection\n",
      "132 frames present\n",
      "5 frames with no detection\n",
      "138 frames present\n",
      "10 frames with no detection\n",
      "117 frames present\n",
      "3 frames with no detection\n",
      "168 frames present\n",
      "12 frames with no detection\n",
      "263 frames present\n",
      "204 frames with no detection\n",
      "165 frames present\n",
      "3 frames with no detection\n",
      "147 frames present\n",
      "4 frames with no detection\n",
      "305 frames present\n",
      "155 frames with no detection\n",
      "148 frames present\n",
      "6 frames with no detection\n",
      "122 frames present\n",
      "2 frames with no detection\n",
      "226 frames present\n",
      "117 frames with no detection\n",
      "123 frames present\n",
      "9 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 13/13 [00:00<00:00, 195.90it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 224.38it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 217.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 frames present\n",
      "0 frames with no detection\n",
      "149 frames present\n",
      "11 frames with no detection\n",
      "145 frames present\n",
      "0 frames with no detection\n",
      "608 frames present\n",
      "467 frames with no detection\n",
      "153 frames present\n",
      "0 frames with no detection\n",
      "46 frames present\n",
      "46 frames with no detection\n",
      "132 frames present\n",
      "7 frames with no detection\n",
      "165 frames present\n",
      "0 frames with no detection\n",
      "148 frames present\n",
      "2 frames with no detection\n",
      "128 frames present\n",
      "0 frames with no detection\n",
      "135 frames present\n",
      "0 frames with no detection\n",
      "116 frames present\n",
      "0 frames with no detection\n",
      "137 frames present\n",
      "4 frames with no detection\n",
      "128 frames present\n",
      "0 frames with no detection\n",
      "106 frames present\n",
      "0 frames with no detection\n",
      "197 frames present\n",
      "11 frames with no detection\n",
      "130 frames present\n",
      "1 frames with no detection\n",
      "152 frames present\n",
      "4 frames with no detection\n",
      "40 frames present\n",
      "40 frames with no detection\n",
      "227 frames present\n",
      "6 frames with no detection\n",
      "388 frames present\n",
      "10 frames with no detection\n",
      "212 frames present\n",
      "6 frames with no detection\n",
      "118 frames present\n",
      "1 frames with no detection\n",
      "138 frames present\n",
      "0 frames with no detection\n",
      "171 frames present\n",
      "16 frames with no detection\n",
      "141 frames present\n",
      "5 frames with no detection\n",
      "130 frames present\n",
      "14 frames with no detection\n",
      "164 frames present\n",
      "0 frames with no detection\n",
      "205 frames present\n",
      "7 frames with no detection\n",
      "499 frames present\n",
      "376 frames with no detection\n",
      "657 frames present\n",
      "504 frames with no detection\n",
      "139 frames present\n",
      "0 frames with no detection\n",
      "142 frames present\n",
      "15 frames with no detection\n",
      "139 frames present\n",
      "6 frames with no detection\n",
      "129 frames present\n",
      "3 frames with no detection\n",
      "116 frames present\n",
      "8 frames with no detection\n",
      "134 frames present\n",
      "4 frames with no detection\n",
      "168 frames present\n",
      "20 frames with no detection\n",
      "114 frames present\n",
      "0 frames with no detection\n",
      "125 frames present\n",
      "2 frames with no detection\n",
      "117 frames present\n",
      "0 frames with no detection\n",
      "11890\n",
      "9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "getparent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-bc4f4d7ab37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerateDataXML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/media/amogh/Stuff/CMU/datasets/bagamoyo_data/openface_outputs/library/openface_199_folders_75_confidence.xml'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'training.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-2e6a3e3833dc>\u001b[0m in \u001b[0;36mgenerateDataXML\u001b[0;34m(list_subject_num, path_data_xml, path_output, subsample)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_ignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mpar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mpar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: getparent"
     ]
    }
   ],
   "source": [
    "generateDataXML([1,2,3,4,5,6],'/media/amogh/Stuff/CMU/datasets/bagamoyo_data/openface_outputs/library/openface_199_folders_75_confidence.xml','training.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [00:00<00:00, 14.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 frames present\n",
      "4 frames with no detection\n",
      "0 frames present\n",
      "0 frames with no detection\n",
      "115 frames present\n",
      "15 frames with no detection\n",
      "143 frames present\n",
      "10 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [00:00<00:00, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 frames present\n",
      "163 frames with no detection\n",
      "118 frames present\n",
      "4 frames with no detection\n",
      "105 frames present\n",
      "7 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [00:00<00:00, 12.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 frames present\n",
      "327 frames with no detection\n",
      "86 frames present\n",
      "86 frames with no detection\n",
      "181 frames present\n",
      "1 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 12.03it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 frames present\n",
      "0 frames with no detection\n",
      "226 frames present\n",
      "6 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:00<00:01, 12.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 frames present\n",
      "0 frames with no detection\n",
      "140 frames present\n",
      "0 frames with no detection\n",
      "95 frames present\n",
      "95 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 6/24 [00:00<00:01, 12.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 frames present\n",
      "0 frames with no detection\n",
      "117 frames present\n",
      "0 frames with no detection\n",
      "67 frames present\n",
      "67 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 10/24 [00:00<00:01, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522 frames present\n",
      "391 frames with no detection\n",
      "81 frames present\n",
      "81 frames with no detection\n",
      "137 frames present\n",
      "0 frames with no detection\n",
      "78 frames present\n",
      "78 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 12/24 [00:00<00:00, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 frames present\n",
      "7 frames with no detection\n",
      "161 frames present\n",
      "3 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 14/24 [00:01<00:00, 12.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 frames present\n",
      "111 frames with no detection\n",
      "109 frames present\n",
      "2 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [00:01<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 frames present\n",
      "77 frames with no detection\n",
      "116 frames present\n",
      "0 frames with no detection\n",
      "72 frames present\n",
      "72 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 20/24 [00:01<00:00, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 frames present\n",
      "10 frames with no detection\n",
      "80 frames present\n",
      "80 frames with no detection\n",
      "149 frames present\n",
      "4 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 22/24 [00:01<00:00, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 frames present\n",
      "81 frames with no detection\n",
      "151 frames present\n",
      "5 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:02<00:00, 10.74it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 frames present\n",
      "302 frames with no detection\n",
      "138 frames present\n",
      "0 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:00<00:00, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 frames present\n",
      "0 frames with no detection\n",
      "102 frames present\n",
      "99 frames with no detection\n",
      "24 frames present\n",
      "24 frames with no detection\n",
      "176 frames present\n",
      "4 frames with no detection\n",
      "117 frames present\n",
      "0 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:00<00:00, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 frames present\n",
      "87 frames with no detection\n",
      "93 frames present\n",
      "93 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 10/10 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 frames present\n",
      "0 frames with no detection\n",
      "130 frames present\n",
      "3 frames with no detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generateDataXML([7,8,9],'/media/amogh/Stuff/CMU/datasets/bagamoyo_data/openface_outputs/library/openface_199_folders_75_confidence.xml','testing.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2008_001322.jpg': <Element 'image' at 0x7ff7b77e4ab0>, '2007_007763.jpg': <Element 'image' at 0x7ff7b77e4e10>, '2008_002079.jpg': <Element 'image' at 0x7ff7b77e4030>, '2008_001009.jpg': <Element 'image' at 0x7ff7b77e4a20>}\n"
     ]
    }
   ],
   "source": [
    "def try1():\n",
    "    tree = ET.parse('/home/amogh/cmu/dlib/examples/faces/training.xml')\n",
    "    root = tree.getroot()\n",
    "    dic = {}\n",
    "    for image in root.iter('image'):\n",
    "        dic[image.attrib['file']] = image\n",
    "    print(dic)\n",
    "try1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
